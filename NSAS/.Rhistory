# Set up fixed data for year being run and load libraries and common data needed
year = 2017
vessel = "lunarBow"
pathIN = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/EV outputs/",sep="")
pathOUT = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/R outputs/",sep="")
pathIN2 = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/Analysis/data files for further analysis in R/",sep="")
################################################################################
# Make data frame with all cells files
# Need to be able to read in all cells files and produce one cells file with all merged
#read in all cell files, process them and merge into dataframe called cells.df
cells.files <- list.files(pathIN,pattern="-ACIN.csv",full.names = TRUE)
cells.list <- lapply(cells.files, function(i) read.csv(i))
# drop superfluous rows and columns
#identify intervals not used (trawls, intertransects etc) and remove
for (i in 1:length(cells.list)){
#identify intervals not used (trawls, intertransects etc) and remove
index<-which(cells.list[[i]]$C_good_samples>0)
cells.list[[i]] <- cells.list[[i]][index,]
rm(index)
# Create unique interval identifier, when exporting in 15min intervals Interval field on its own is unique across the series. when exporting in 1nm, need to combine process id field and Interval number
cells.list[[i]]$ID <- paste(cells.list[[i]]$Date_M,"_",formatC(cells.list[[i]][,2], width=3, flag="0"),"_",formatC(cells.list[[i]][,3], width=3, flag="0"),sep="")
#now retain only columns of interest for further analysis
cells.list[[i]]<- cells.list[[i]][,c("ID","Time_M","Date_M","Lat_M","Lon_M","C_good_samples","C_bad_data_no_data_samples")]
#format time
cells.list[[i]]$Time_M <- round.POSIXt(strptime(cells.list[[i]]$Time_M,format="%H:%M:%S"),units=c("mins"))
#Format date
cells.list[[i]]$Date <- paste(substr(cells.list[[i]]$Date_M,7,8),"/",substr(cells.list[[i]]$Date_M,5,6),"/",substr(cells.list[[i]]$Date_M,1,4),sep="")
cells.list[[i]]$T_diff <- 0
#  for (a in 1:length(cells.list[[i]]$Time_E))
#    {
#    cells.list[[i]]$T_diff[a] <- cells.list[[i]]$Time_E[a]-cells.list[[i]]$Time_S[a+1]
#    }
#  cells.list[[i]]$Tx <- 0
#    for (a in 1:length(cells.list[[i]]$Time_E))
#    {
#    cells.list[[i]]$Tx[a] <- cells.list[[i]]$Time_E[a]-cells.list[[i]]$Time_S[a]
#    }
cells.list[[i]]$Time_M <- substr(cells.list[[i]]$Time_M,12,16)
}
i
###############################################################################
#
# Script for processing echoview outputs and producing text file to feed into StoX and R script
# for biomass estimation - Survey July 2017
#
# Susan M Lusseau - 11/11/2015
# modified to 2016 survey on Scotia 08/11/2016
# modified to 2017 survey on Scotia 07/11/2017
#
# Build in v 3.1.3
# Compatibel with Echoview 6.1 outputs, also EV8
# Based on script "EV out file reader scotia 2015"
#
################################################################################
rm(list=ls())
# Set up fixed data for year being run and load libraries and common data needed
year = 2017
vessel = "lunarBow"
pathIN = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/EV outputs/",sep="")
pathOUT = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/R outputs/",sep="")
pathIN2 = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/Analysis/data files for further analysis in R/",sep="")
################################################################################
# Make data frame with all cells files
# Need to be able to read in all cells files and produce one cells file with all merged
#read in all cell files, process them and merge into dataframe called cells.df
cells.files <- list.files(pathIN,pattern="-ACIN.csv",full.names = TRUE)
cells.list <- lapply(cells.files, function(i) read.csv(i))
i<=2
i<-2
#identify intervals not used (trawls, intertransects etc) and remove
index<-which(cells.list[[i]]$C_good_samples>0)
cells.list[[i]] <- cells.list[[i]][index,]
rm(index)
cells.list[[i]]$ID <- paste(cells.list[[i]]$Date_M,"_",formatC(cells.list[[i]][,2], width=3, flag="0"),"_",formatC(cells.list[[i]][,3], width=3, flag="0"),sep="")
paste(cells.list[[i]]$Date_M,"_",formatC(cells.list[[i]][,2], width=3, flag="0"),"_",formatC(cells.list[[i]][,3], width=3, flag="0"),sep="")
a <-paste(cells.list[[i]]$Date_M,"_",formatC(cells.list[[i]][,2], width=3, flag="0"),"_",formatC(cells.list[[i]][,3], width=3, flag="0"),sep="")
i<-1
index<-which(cells.list[[i]]$C_good_samples>0)
cells.list[[i]] <- cells.list[[i]][index,]
rm(index)
# Create unique interval identifier, when exporting in 15min intervals Interval field on its own is unique across the series. when exporting in 1nm, need to combine process id field and Interval number
cells.list[[i]]$ID <- paste(cells.list[[i]]$Date_M,"_",formatC(cells.list[[i]][,2], width=3, flag="0"),"_",formatC(cells.list[[i]][,3], width=3, flag="0"),sep="")
a <-paste(cells.list[[i]]$Date_M,"_",formatC(cells.list[[i]][,2], width=3, flag="0"),"_",formatC(cells.list[[i]][,3], width=3, flag="0"),sep="")
View(cells.list)
a
i<-2
cells.list[[i]]$Date_M
cells.list[[i]]
cells.list[[1]]
cells.list[[2]]
View(cells.list)
###############################################################################
#
# Script for processing echoview outputs and producing text file to feed into StoX and R script
# for biomass estimation - Survey July 2017
#
# Susan M Lusseau - 11/11/2015
# modified to 2016 survey on Scotia 08/11/2016
# modified to 2017 survey on Scotia 07/11/2017
#
# Build in v 3.1.3
# Compatibel with Echoview 6.1 outputs, also EV8
# Based on script "EV out file reader scotia 2015"
#
################################################################################
rm(list=ls())
# Set up fixed data for year being run and load libraries and common data needed
year = 2017
vessel = "lunarBow"
pathIN = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/EV outputs/",sep="")
pathOUT = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/R outputs/",sep="")
pathIN2 = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/Analysis/data files for further analysis in R/",sep="")
################################################################################
# Make data frame with all cells files
# Need to be able to read in all cells files and produce one cells file with all merged
#read in all cell files, process them and merge into dataframe called cells.df
cells.files <- list.files(pathIN,pattern="-ACIN.csv",full.names = TRUE)
cells.list <- lapply(cells.files, function(i) read.csv(i))
cells.list[[2]]
i<-1
index<-which(cells.list[[i]]$C_good_samples>0)
cells.list[[i]] <- cells.list[[i]][index,]
rm(index)
cells.list[[2]]
i<-2
index<-which(cells.list[[i]]$C_good_samples>0)
cells.list[[i]] <- cells.list[[i]][index,]
rm(index)
cells.list[[2]]
cells.list[[i1]$C_good_samples
cells.list[[1]$C_good_samples
cells.list[[1]]$C_good_samples
cells.list[[2]]$C_good_samples
###############################################################################
#
# Script for processing echoview outputs and producing text file to feed into StoX and R script
# for biomass estimation - Survey July 2017
#
# Susan M Lusseau - 11/11/2015
# modified to 2016 survey on Scotia 08/11/2016
# modified to 2017 survey on Scotia 07/11/2017
#
# Build in v 3.1.3
# Compatibel with Echoview 6.1 outputs, also EV8
# Based on script "EV out file reader scotia 2015"
#
################################################################################
rm(list=ls())
# Set up fixed data for year being run and load libraries and common data needed
year = 2017
vessel = "lunarBow"[]
pathIN = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/EV outputs/",sep="")
pathOUT = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/R outputs/",sep="")
pathIN2 = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/Analysis/data files for further analysis in R/",sep="")
################################################################################
# Make data frame with all cells files
# Need to be able to read in all cells files and produce one cells file with all merged
#read in all cell files, process them and merge into dataframe called cells.df
cells.files <- list.files(pathIN,pattern="-ACIN.csv",full.names = TRUE)
cells.list <- lapply(cells.files, function(i) read.csv(i))
cells.list[[2]]$C_good_samples
View(cells.list)
View(cells.list)
###############################################################################
#
# Script for processing echoview outputs and producing text file to feed into StoX and R script
# for biomass estimation - Survey July 2017
#
# Susan M Lusseau - 11/11/2015
# modified to 2016 survey on Scotia 08/11/2016
# modified to 2017 survey on Scotia 07/11/2017
#
# Build in v 3.1.3
# Compatibel with Echoview 6.1 outputs, also EV8
# Based on script "EV out file reader scotia 2015"
#
################################################################################
rm(list=ls())
# Set up fixed data for year being run and load libraries and common data needed
year = 2017
vessel = "lunarBow"[]
pathIN = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/EV outputs/",sep="")
pathOUT = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/R outputs/",sep="")
pathIN2 = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/Analysis/data files for further analysis in R/",sep="")
################################################################################
# Make data frame with all cells files
# Need to be able to read in all cells files and produce one cells file with all merged
#read in all cell files, process them and merge into dataframe called cells.df
cells.files <- list.files(pathIN,pattern="-ACIN.csv",full.names = TRUE)
cells.list <- lapply(cells.files, function(i) read.csv(i))
i<-2
index<-which(cells.list[[i]]$C_good_samples>0)
cells.list[[i]] <- cells.list[[i]][index,]
rm(index)
cells.list
# Create unique interval identifier, when exporting in 15min intervals Interval field on its own is unique across the series. when exporting in 1nm, need to combine process id field and Interval number
cells.list[[i]]$ID <- paste(cells.list[[i]]$Date_M,"_",formatC(cells.list[[i]][,2], width=3, flag="0"),"_",formatC(cells.list[[i]][,3], width=3, flag="0"),sep="")
#now retain only columns of interest for further analysis
cells.list[[i]]<- cells.list[[i]][,c("ID","Time_M","Date_M","Lat_M","Lon_M","C_good_samples","C_bad_data_no_data_samples")]
#format time
cells.list[[i]]$Time_M <- round.POSIXt(strptime(cells.list[[i]]$Time_M,format="%H:%M:%S"),units=c("mins"))
#Format date
cells.list[[i]]$Date <- paste(substr(cells.list[[i]]$Date_M,7,8),"/",substr(cells.list[[i]]$Date_M,5,6),"/",substr(cells.list[[i]]$Date_M,1,4),sep="")
cells.list[[i]]$T_diff <- 0
#  for (a in 1:length(cells.list[[i]]$Time_E))
#    {
#    cells.list[[i]]$T_diff[a] <- cells.list[[i]]$Time_E[a]-cells.list[[i]]$Time_S[a+1]
#    }
#  cells.list[[i]]$Tx <- 0
#    for (a in 1:length(cells.list[[i]]$Time_E))
#    {
#    cells.list[[i]]$Tx[a] <- cells.list[[i]]$Time_E[a]-cells.list[[i]]$Time_S[a]
#    }
cells.list[[i]]$Time_M <- substr(cells.list[[i]]$Time_M,12,16)
cells.list[[i]]$ID <- paste(cells.list[[i]]$Date_M,"_",formatC(cells.list[[i]][,2], width=3, flag="0"),"_",formatC(cells.list[[i]][,3], width=3, flag="0"),sep="")
cells.list[[i]]$Date_M
cells.list[[i]]
###############################################################################
#
# Script for processing echoview outputs and producing text file to feed into StoX and R script
# for biomass estimation - Survey July 2017
#
# Susan M Lusseau - 11/11/2015
# modified to 2016 survey on Scotia 08/11/2016
# modified to 2017 survey on Scotia 07/11/2017
#
# Build in v 3.1.3
# Compatibel with Echoview 6.1 outputs, also EV8
# Based on script "EV out file reader scotia 2015"
#
################################################################################
rm(list=ls())
# Set up fixed data for year being run and load libraries and common data needed
year = 2017
vessel = "lunarBow"[]
pathIN = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/EV outputs/",sep="")
pathOUT = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/R outputs/",sep="")
pathIN2 = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/Analysis/data files for further analysis in R/",sep="")
################################################################################
# Make data frame with all cells files
# Need to be able to read in all cells files and produce one cells file with all merged
#read in all cell files, process them and merge into dataframe called cells.df
cells.files <- list.files(pathIN,pattern="-ACIN.csv",full.names = TRUE)
cells.list <- lapply(cells.files, function(i) read.csv(i))
###############################################################################
#
# Script for processing echoview outputs and producing text file to feed into StoX and R script
# for biomass estimation - Survey July 2017
#
# Susan M Lusseau - 11/11/2015
# modified to 2016 survey on Scotia 08/11/2016
# modified to 2017 survey on Scotia 07/11/2017
#
# Build in v 3.1.3
# Compatibel with Echoview 6.1 outputs, also EV8
# Based on script "EV out file reader scotia 2015"
#
################################################################################
rm(list=ls())
# Set up fixed data for year being run and load libraries and common data needed
year = 2017
vessel = "lunarBow"[]
pathIN = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/EV outputs/",sep="")
pathOUT = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/R outputs/",sep="")
pathIN2 = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/Analysis/data files for further analysis in R/",sep="")
################################################################################
# Make data frame with all cells files
# Need to be able to read in all cells files and produce one cells file with all merged
#read in all cell files, process them and merge into dataframe called cells.df
cells.files <- list.files(pathIN,pattern="-ACIN.csv",full.names = TRUE)
cells.list <- lapply(cells.files, function(i) read.csv(i))
###############################################################################
#
# Script for processing echoview outputs and producing text file to feed into StoX and R script
# for biomass estimation - Survey July 2017
#
# Susan M Lusseau - 11/11/2015
# modified to 2016 survey on Scotia 08/11/2016
# modified to 2017 survey on Scotia 07/11/2017
#
# Build in v 3.1.3
# Compatibel with Echoview 6.1 outputs, also EV8
# Based on script "EV out file reader scotia 2015"
#
################################################################################
rm(list=ls())
# Set up fixed data for year being run and load libraries and common data needed
year = 2017
vessel = "lunarBow"[]
pathIN = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/EV outputs/",sep="")
pathOUT = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/R outputs/",sep="")
pathIN2 = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/Analysis/data files for further analysis in R/",sep="")
################################################################################
# Make data frame with all cells files
# Need to be able to read in all cells files and produce one cells file with all merged
#read in all cell files, process them and merge into dataframe called cells.df
cells.files <- list.files(pathIN,pattern="-ACIN.csv",full.names = TRUE)
cells.list <- lapply(cells.files, function(i) read.csv(i))
cells.list[[2]]$C_good_samples
i<-2
index<-which(cells.list[[i]]$C_good_samples>0)
cells.list[[i]] <- cells.list[[i]][index,]
rm(index)
cells.list[[i]]$ID <- paste(cells.list[[i]]$Date_M,"_",formatC(cells.list[[i]][,2], width=3, flag="0"),"_",formatC(cells.list[[i]][,3], width=3, flag="0"),sep="")
###############################################################################
#
# Script for processing echoview outputs and producing text file to feed into StoX and R script
# for biomass estimation - Survey July 2017
#
# Susan M Lusseau - 11/11/2015
# modified to 2016 survey on Scotia 08/11/2016
# modified to 2017 survey on Scotia 07/11/2017
#
# Build in v 3.1.3
# Compatibel with Echoview 6.1 outputs, also EV8
# Based on script "EV out file reader scotia 2015"
#
################################################################################
rm(list=ls())
# Set up fixed data for year being run and load libraries and common data needed
year = 2017
vessel = "lunarBow"[]
pathIN = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/EV outputs/",sep="")
pathOUT = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/R outputs/",sep="")
pathIN2 = paste("D:/OneDrive/OneDrive - WageningenUR/projects/surveys/herring6a/data/echoview/Analysis/Analysis/data files for further analysis in R/",sep="")
################################################################################
# Make data frame with all cells files
# Need to be able to read in all cells files and produce one cells file with all merged
#read in all cell files, process them and merge into dataframe called cells.df
cells.files <- list.files(pathIN,pattern="-ACIN.csv",full.names = TRUE)
cells.list <- lapply(cells.files, function(i) read.csv(i))
# drop superfluous rows and columns
#identify intervals not used (trawls, intertransects etc) and remove
for (i in 1:length(cells.list)){
#identify intervals not used (trawls, intertransects etc) and remove
index<-which(cells.list[[i]]$C_good_samples>0)
cells.list[[i]] <- cells.list[[i]][index,]
rm(index)
# Create unique interval identifier, when exporting in 15min intervals Interval field on its own is unique across the series. when exporting in 1nm, need to combine process id field and Interval number
cells.list[[i]]$ID <- paste(cells.list[[i]]$Date_M,"_",formatC(cells.list[[i]][,2], width=3, flag="0"),"_",formatC(cells.list[[i]][,3], width=3, flag="0"),sep="")
#now retain only columns of interest for further analysis
cells.list[[i]]<- cells.list[[i]][,c("ID","Time_M","Date_M","Lat_M","Lon_M","C_good_samples")]
#format time
cells.list[[i]]$Time_M <- round.POSIXt(strptime(cells.list[[i]]$Time_M,format="%H:%M:%S"),units=c("mins"))
#Format date
cells.list[[i]]$Date <- paste(substr(cells.list[[i]]$Date_M,7,8),"/",substr(cells.list[[i]]$Date_M,5,6),"/",substr(cells.list[[i]]$Date_M,1,4),sep="")
cells.list[[i]]$T_diff <- 0
#  for (a in 1:length(cells.list[[i]]$Time_E))
#    {
#    cells.list[[i]]$T_diff[a] <- cells.list[[i]]$Time_E[a]-cells.list[[i]]$Time_S[a+1]
#    }
#  cells.list[[i]]$Tx <- 0
#    for (a in 1:length(cells.list[[i]]$Time_E))
#    {
#    cells.list[[i]]$Tx[a] <- cells.list[[i]]$Time_E[a]-cells.list[[i]]$Time_S[a]
#    }
cells.list[[i]]$Time_M <- substr(cells.list[[i]]$Time_M,12,16)
}
cells.df <- do.call('rbind', cells.list)
head(cells.df)
# Use ratio of good data samples to total number of samples in interval to approximate logint. Majority should be 1.
cells.df$Log_int<- round(cells.df$C_good_samples/(cells.df$C_good_samples+cells.df$C_bad_data_no_data_samples),1)
plot(cells.df$Log_int)
# locate and remove intervals where position = 999. These seem to be at the start and end of the day where start and end of echogram is within the first or last interval.
# check before excluding though!
# Locate and check intervals affected
index<-which(cells.df$Lat_E==999|cells.df$Lat_S==999)
cells.df[index,];cells.df$ID[index]
#if happy to remove these (if they are very small, and at end/start of day) proceed, but keep track of intervals removed for later:
cells.out<-cells.df$ID[index]
cells.df<-cells.df[-index,]
head(cells.df)
View(cells.df)
View(cells.df)
cells.df <- do.call('rbind', cells.list)
View(cells.df)
cells.df <- cells.df[order(cells.df$ID),]
cells.df$LOG[1]<-cells.df$Log_int[1]
for (i in 2:dim(cells.df)[1])
{
cells.df$LOG[i] <- cells.df$LOG[i-1]+cells.df$Log_int[i]
}
head(cells.df)
tail(cells.df)
write.csv(cells.df,paste(pathOUT,vessel,"_",year,"_cells_v2.csv",sep=""),row.names = F)
cells.out
reg.files <- list.files(pathIN,pattern="-ABIN.csv",full.names = TRUE)
reg.list <- lapply(reg.files, function(i) read.csv(i) )
# take out non sensical regions based on region_ID == -9999
for (i in 1:length(reg.list)){
index<- which(reg.list[[i]][,1]!=-9999)
reg.list[[i]]$ID<-paste(reg.list[[i]]$Date_M,"_",formatC(reg.list[[i]]$Interval, width=3, flag="0"),"_",formatC(reg.list[[i]]$Layer, width=3, flag="0"),sep="")
reg.list[[i]]<- reg.list[[i]][index,c("ID","Time_S","Region_class","PRC_NASC","Sv_max")]
rm(index)
}
install.packages("plotrix")
set.seed(101)
help.start()
frogs = c(1.1,1.3
1.7,1.8,1.9,2.1,2.3,2.4,2.5
frogs = c(1.1,1.3,1.7,1.8,1.9,2.1,2.3,2.4,2.5,2.8,3.1,3.3,3.6,3.7,3.9,4.1,4.5,4.8,5.1,5.3)
View(coast)
frogs
tadpoles=rnorm(n=20,mean=2*frogs,sd=0.5)
2*frogs
mean(2*frogs)
tadpoles
plot(frogs,tadpoles)
install.packages("FLCore", repos="http://flr-project.org/R")
install.packages("FLSAM", repos="http://flr-project.org/R")
library(FLSAM)
install.packages("FLSAM", repos="http://flr-project.org/R")
install.packages("FLSAM", repos="http://flr-project.org/R")
library(FLSAM)
library(FLBRP)
install.packages("FLBRP", repos="http://flr-project.org/R")
install.packages("ggplotFL", repos="http://flr-project.org/R")
install.packages("ggplot2")
.libPath()
.libPaths()
.libPaths('C:/Program Files/R/R-3.3.3/library')
.libPaths()
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
install.packages("ggplot2")
.libPaths()
.libPaths("C:/Program Files/R/R-3.3.3/library")
.libPaths()
install.packages("ggplot2")
install.packages("FLCore", repos="http://flr-project.org/R")
install.packages("ggplotFL", repos="http://flr-project.org/R")
install.packages("gridExtra")
install.packages("ggplotFL", repos="http://flr-project.org/R")
install.packages("FLa4a", repos="http://flr-project.org/R")
install.packages("triangle")
install.packages("copula")
install.packages("coda")
install.packages("FLa4a", repos="http://flr-project.org/R")
install.packages("FLBRP", repos="http://flr-project.org/R")
install.packages("reshape")
install.packages("FLBRP", repos="http://flr-project.org/R")
install.packages("FLash", repos="http://flr-project.org/R")
install.packages("FLash", repos="http://flr-project.org/R")
install.packages("FLFleet", repos="http://flr-project.org/R")
install.packages("FLBEIA", repos="http://flr-project.org/R")
install.packages("FLSAM", repos="http://flr-project.org/R")
install.packages("FLXSA", repos="http://flr-project.org/R")
install.packages("FLAssess", repos="http://flr-project.org/R")
install.packages("FLRDynState", repos="http://flr-project.org/R")
install.packages("kobe", repos="http://flr-project.org/R")
install.packages("emdbook")
install.packages("kobe", repos="http://flr-project.org/R")
install.packages("FLife", repos="http://flr-project.org/R")
install.packages("popbio")
install.packages("diags", repos="http://flr-project.org/R")
install.packages("mpb", repos="http://flr-project.org/R")
install.packages("mse", repos="http://flr-project.org/R")
install.packages("FLasher", repos="http://flr-project.org/R")
library(FLSAM)
source("http://flr-project.org/R/instFLR.R")
.libPaths()
################################################################################
# NSH_SAM Assessment
#
# $Rev: 697 $
# $Date: 2012-02-10 09:52:28 +0100 (vr, 10 feb 2012) $
#
# Author: HAWG model devlopment group
#
# Performs the "Final" assessment for NSAS assessment
#
# Developed with:
#   - R version 2.13.0
#   - FLCore 2.4
#
# To be done:
#
# Notes: Have fun running this assessment!
#
################################################################################
### ============================================================================
### ============================================================================
### ============================================================================
### Setup
### ============================================================================
### ============================================================================
### ============================================================================
rm(list=ls()); graphics.off(); start.time <- proc.time()[3]
options(stringsAsFactors=FALSE)
log.msg     <-  function(string) {cat(string);}
log.msg("\nNSH Final Assessment\n=====================\n")
# local path
path <- "D:/git/wg_HAWG/NSAS/"
try(setwd(path),silent=TRUE)
### ======================================================================================================
### Define parameters and paths for use in the assessment code
### ======================================================================================================
output.dir          <-  file.path(".","results")                #figures directory
output.base         <-  file.path(output.dir,"NSH Assessment")  #Output base filename, including directory. Other output filenames are built by appending onto this one
n.retro.years       <-  10                                      #Number of years for which to run the retrospective
.libPaths("C:/software/Rpackages")
### ============================================================================
### imports
### ============================================================================
library(FLSAM); library(FLEDA)
.libPaths()
install.packages("FLEDA", repos="http://flr-project.org/R")
library(FLEDA)
install.packages("FLAssess", repos="http://flr-project.org/R")
install.packages("FLash", repos="http://flr-project.org/R")
source("http://flr-project.org/R/instFLR.R")
